{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77f66dbe-192b-471c-9cb8-e9b365e61bbb",
   "metadata": {},
   "source": [
    "# Lab | Tools prompting\n",
    "\n",
    "**Replace the existing two tools decorators, by creating 3 new ones and adjust the prompts accordingly**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b94240",
   "metadata": {},
   "source": [
    "### How to add ad-hoc tool calling capability to LLMs and Chat Models\n",
    "\n",
    ":::{.callout-caution}\n",
    "\n",
    "Some models have been fine-tuned for tool calling and provide a dedicated API for tool calling. Generally, such models are better at tool calling than non-fine-tuned models, and are recommended for use cases that require tool calling. Please see the [how to use a chat model to call tools](https://python.langchain.com/docs/how_to/tool_calling/) guide for more information.\n",
    "\n",
    "In this guide, we'll see how to add **ad-hoc** tool calling support to a chat model. This is an alternative method to invoke tools if you're using a model that does not natively support tool calling.\n",
    "\n",
    "We'll do this by simply writing a prompt that will get the model to invoke the appropriate tools. Here's a diagram of the logic:\n",
    "\n",
    "<br>\n",
    "\n",
    "![chain](https://education-team-2020.s3.eu-west-1.amazonaws.com/ai-eng/tool_chain.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a22cb8-19e7-450a-9d1b-6848d2c81cd1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We'll need to install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c556c5e-b785-428b-8e7d-efd34a2a1adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet langchain langchain-community langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897bc01e-cc2b-4400-8a64-db4aa56085d3",
   "metadata": {},
   "source": [
    "If you'd like to use LangSmith, uncomment the below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5efb4170-b95b-4d29-8f57-09509f3ba6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec6409b-21e5-4d0a-8a46-c4ef0b055dd3",
   "metadata": {},
   "source": [
    "You can select any of the given models for this how-to guide. Keep in mind that most of these models already [support native tool calling](https://python.langchain.com/docs/integrations/chat), so using the prompting strategy shown here doesn't make sense for these models, and instead you should follow the [how to use a chat model to call tools](https://python.langchain.com/docs/how_to/tool_calling/) guide.\n",
    "\n",
    "```{=mdx}\n",
    "import ChatModelTabs from \"@theme/ChatModelTabs\";\n",
    "\n",
    "<ChatModelTabs openaiParams={`model=\"gpt-4\"`} />\n",
    "```\n",
    "\n",
    "To illustrate the idea, we'll use `phi3` via Ollama, which does **NOT** have native support for tool calling. If you'd like to use `Ollama` as well follow [these instructions](https://python.langchain.com/docs/integrations/chat/ollama)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "424be968-2806-4d1a-a6aa-5499ae20fac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adria\\AppData\\Local\\Temp\\ipykernel_15664\\1427064109.py:3: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the `langchain-ollama package and should be used instead. To use it run `pip install -U `langchain-ollama` and import as `from `langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=\"phi3\")\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "model = Ollama(model=\"phi3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a1463",
   "metadata": {},
   "source": [
    "\n",
    "#  How to Install and Run Ollama with the Phi-3 Model\n",
    "\n",
    "This guide walks you through installing **Ollama** and running the **Phi-3** model on Windows, macOS, and Linux.\n",
    "\n",
    "---\n",
    "\n",
    "## Windows\n",
    "\n",
    "1. **Download Ollama for Windows**  \n",
    "   Go to: [https://ollama.com/download](https://ollama.com/download)  \n",
    "   Download and run the installer.\n",
    "\n",
    "2. **Verify Installation**  \n",
    "   Open **Command Prompt** and type:\n",
    "   ```bash\n",
    "   ollama --version\n",
    "   ```\n",
    "\n",
    "3. **Run the Phi-3 Model**  \n",
    "   In the same terminal:\n",
    "   ```bash\n",
    "   ollama run phi3\n",
    "   ```\n",
    "\n",
    "4. **If you get a CUDA error (GPU memory issue)**  \n",
    "   Run Ollama in **CPU mode**:\n",
    "   ```bash\n",
    "   set OLLAMA_NO_CUDA=1\n",
    "   ollama run phi3\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "##  macOS\n",
    "\n",
    "1. **Install via Homebrew**  \n",
    "   Open the Terminal and run:\n",
    "   ```bash\n",
    "   brew install ollama\n",
    "   ```\n",
    "\n",
    "2. **Run the Phi-3 Model**\n",
    "   ```bash\n",
    "   ollama run phi3\n",
    "   ```\n",
    "\n",
    "3. **To force CPU mode (no GPU)**\n",
    "   ```bash\n",
    "   export OLLAMA_NO_CUDA=1\n",
    "   ollama run phi3\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "##  Linux\n",
    "\n",
    "1. **Install Ollama**  \n",
    "   Open a terminal and run:\n",
    "   ```bash\n",
    "   curl -fsSL https://ollama.com/install.sh | sh\n",
    "   ```\n",
    "\n",
    "2. **Run the Phi-3 Model**\n",
    "   ```bash\n",
    "   ollama run phi3\n",
    "   ```\n",
    "\n",
    "3. **To force CPU mode (no GPU)**\n",
    "   ```bash\n",
    "   export OLLAMA_NO_CUDA=1\n",
    "   ollama run phi3\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "##  Notes\n",
    "\n",
    "- The first time you run `ollama run phi3`, it will **download the model**, so make sure you‚Äôre connected to the internet.\n",
    "- Once downloaded, it works **offline**.\n",
    "- Keep the terminal open and running in the background while using Ollama from your code or notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68946881",
   "metadata": {},
   "source": [
    "## Create a tool\n",
    "\n",
    "First, let's create an `add` and `multiply` tools. For more information on creating custom tools, please see [this guide](https://python.langchain.com/docs/how_to/custom_tools/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4548e6fa-0f9b-4d7a-8fa5-66cec0350e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "divide\n",
      "Divide two numbers together.\n",
      "{'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}\n",
      "--\n",
      "rest\n",
      "Add two numbers.\n",
      "{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}\n",
      "--\n",
      "power\n",
      "Raise a number to a given exponent.\n",
      "{'base': {'title': 'Base', 'type': 'number'}, 'exponent': {'title': 'Exponent', 'type': 'number'}}\n",
      "--\n",
      "modulo\n",
      "Return the remainder of dividing x by y.\n",
      "{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def divide(x: float, y: float) -> float:\n",
    "    \"\"\"Divide two numbers together.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "\n",
    "@tool\n",
    "def rest(x: int, y: int) -> int:\n",
    "    \"Add two numbers.\"\n",
    "    return x - y\n",
    "\n",
    "@tool\n",
    "def power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Raise a number to a given exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "\n",
    "@tool\n",
    "def modulo(x: int, y: int) -> int:\n",
    "    \"\"\"Return the remainder of dividing x by y.\"\"\"\n",
    "    return x % y\n",
    "\n",
    "\n",
    "tools = [divide, rest, power, modulo]\n",
    "\n",
    "# Let's inspect the tools\n",
    "for t in tools:\n",
    "    print(\"--\")\n",
    "    print(t.name)\n",
    "    print(t.description)\n",
    "    print(t.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be77e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "divide.invoke({\"x\": 4, \"y\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd690e-e54d-4209-91a4-181f69a452ac",
   "metadata": {},
   "source": [
    "## Creating our prompt\n",
    "\n",
    "We'll want to write a prompt that specifies the tools the model has access to, the arguments to those tools, and the desired output format of the model. In this case we'll instruct it to output a JSON blob of the form `{\"name\": \"...\", \"arguments\": {...}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2063b564-25ca-4729-a45f-ba4633175b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divide(x: float, y: float) -> float - Divide two numbers together.\n",
      "rest(x: int, y: int) -> int - Add two numbers.\n",
      "power(base: float, exponent: float) -> float - Raise a number to a given exponent.\n",
      "modulo(x: int, y: int) -> int - Return the remainder of dividing x by y.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import render_text_description\n",
    "\n",
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f02f1dce-76e7-4ca9-9bac-5af496131fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\\\n",
    "You are an assistant that has access to the following set of tools. \n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. \n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "\n",
    "The `arguments` should be a dictionary, with keys corresponding \n",
    "to the argument names and the values corresponding to the requested values.\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8623e03-60eb-4439-b57b-ecbcebc61b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"name\": \"power\",\n",
      "  \"arguments\": {\n",
      "    \"base\": 3,\n",
      "    \"exponent\": 4\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | model\n",
    "message = chain.invoke({\"input\": \"what's 3 powered to 4?\"})\n",
    "\n",
    "# Let's take a look at the output from the model\n",
    "# if the model is an LLM (not a chat model), the output will be a string.\n",
    "if isinstance(message, str):\n",
    "    print(message)\n",
    "else:  # Otherwise it's a chat model\n",
    "    print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14df2cd5-b6fa-4b10-892d-e8692c7931e5",
   "metadata": {},
   "source": [
    "## Adding an output parser\n",
    "\n",
    "We'll use the `JsonOutputParser` for parsing our models output to JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f129f5bd-127c-4c95-8f34-8f437da7ca8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'modulo', 'arguments': {'x': 13, 'y': 4}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "chain = prompt | model | JsonOutputParser()\n",
    "chain.invoke({\"input\": \"what's thirteen modulo four?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f08255-f146-4f4a-be43-5c21c1d3ae83",
   "metadata": {},
   "source": [
    ":::{.callout-important}\n",
    "\n",
    "üéâ Amazing! üéâ We now instructed our model on how to **request** that a tool be invoked.\n",
    "\n",
    "Now, let's create some logic to actually run the tool!\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e29dd4c-8eb5-457f-92d1-8add076404dc",
   "metadata": {},
   "source": [
    "## Invoking the tool üèÉ\n",
    "\n",
    "Now that the model can request that a tool be invoked, we need to write a function that can actually invoke \n",
    "the tool.\n",
    "\n",
    "The function will select the appropriate tool by name, and pass to it the arguments chosen by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faee95e0-4095-4310-991f-9e9465c6738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional, TypedDict\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "\n",
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "def invoke_tool(\n",
    "    tool_call_request: ToolCallRequest, config: Optional[RunnableConfig] = None\n",
    "):\n",
    "    \"\"\"A function that we can use the perform a tool invocation.\n",
    "\n",
    "    Args:\n",
    "        tool_call_request: a dict that contains the keys name and arguments.\n",
    "            The name must match the name of a tool that exists.\n",
    "            The arguments are the arguments to that tool.\n",
    "        config: This is configuration information that LangChain uses that contains\n",
    "            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n",
    "\n",
    "    Returns:\n",
    "        output from the requested tool\n",
    "    \"\"\"\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "    name = tool_call_request[\"name\"]\n",
    "    requested_tool = tool_name_to_tool[name]\n",
    "    return requested_tool.invoke(tool_call_request[\"arguments\"], config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4957532-9e0c-47f6-bb62-0fd789ac1d3e",
   "metadata": {},
   "source": [
    "Let's test this out üß™!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0ea3b2a-8fb2-4016-83c8-a5d3e78fedbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "243.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoke_tool({\"name\": \"power\", \"arguments\": {\"base\": 3, \"exponent\": 5}})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715af6e1-935d-4bc0-a3d2-646ecf8a329b",
   "metadata": {},
   "source": [
    "## Let's put it together\n",
    "\n",
    "Let's put it together into a chain that creates a calculator with add and multiplication capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0555b384-fde6-4404-86e0-7ea199003d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1298.7012987012988"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | JsonOutputParser() | invoke_tool\n",
    "chain.invoke({\"input\": \"what's 100000 divided by 77\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9c5aa-f60a-4017-af6f-1ff6e04bfb61",
   "metadata": {},
   "source": [
    "## Returning tool inputs\n",
    "\n",
    "It can be helpful to return not only tool outputs but also tool inputs. We can easily do this with LCEL by `RunnablePassthrough.assign`-ing the tool output. This will take whatever the input is to the RunnablePassrthrough components (assumed to be a dictionary) and add a key to it while still passing through everything that's currently in the input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45404406-859d-4caa-8b9d-5838162c80a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'rest', 'arguments': {'x': 5, 'y': 3}, 'output': 2}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    prompt | model | JsonOutputParser() | RunnablePassthrough.assign(output=invoke_tool)\n",
    ")\n",
    "chain.invoke({\"input\": \"what's thirteen times 4.14137281\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1797fe82-ea35-4cba-834a-1caf9740d184",
   "metadata": {},
   "source": [
    "## What's next?\n",
    "\n",
    "This how-to guide shows the \"happy path\" when the model correctly outputs all the required tool information.\n",
    "\n",
    "In reality, if you're using more complex tools, you will start encountering errors from the model, especially for models that have not been fine tuned for tool calling and for less capable models.\n",
    "\n",
    "You will need to be prepared to add strategies to improve the output from the model; e.g.,\n",
    "\n",
    "1. Provide few shot examples.\n",
    "2. Add error handling (e.g., catch the exception and feed it back to the LLM to ask it to correct its previous output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b759db45",
   "metadata": {},
   "source": [
    "FEW SHOT EXAMPLES FOR ALL TOOLS:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e245334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "     You are a helpful assistant with access to mathematical tools.\n",
    "     Always respond using a JSON object with:\n",
    "     - \"tool\": <tool_name>\n",
    "     - \"args\": <argument dictionary>\n",
    "     \n",
    "     Tools available:\n",
    "     1. divide(x, y) ‚Üí divide two numbers\n",
    "     2. rest(x, y) ‚Üí subtract y from x\n",
    "     3. power(base, exponent) ‚Üí raise base to exponent\n",
    "     4. modulo(x, y) ‚Üí return x mod y\n",
    "\n",
    "     --- EXAMPLES ---\n",
    "\n",
    "     USER: What is 10 divided by 2?\n",
    "     ASSISTANT: ```json\n",
    "     { \"tool\": \"divide\", \"args\": {\"x\": 10, \"y\": 2} }\n",
    "     ```\n",
    "\n",
    "     USER: subtract 5 minus 3\n",
    "     ASSISTANT: ```json\n",
    "     { \"tool\": \"rest\", \"args\": {\"x\": 5, \"y\": 3} }\n",
    "     ```\n",
    "\n",
    "     USER: compute 2 raised to the power of 8\n",
    "     ASSISTANT: ```json\n",
    "     { \"tool\": \"power\", \"args\": {\"base\": 2, \"exponent\": 8} }\n",
    "     ```\n",
    "\n",
    "     USER: what is 17 mod 5?\n",
    "     ASSISTANT: ```json\n",
    "     { \"tool\": \"modulo\", \"args\": {\"x\": 17, \"y\": 5} }\n",
    "     ```\n",
    "\n",
    "     --- END EXAMPLES ---\n",
    "\n",
    "     Follow EXACTLY the same JSON structure.\n",
    "     No explanation, no extra text.\n",
    "     \"\"\"\n",
    "    ),\n",
    "\n",
    "    (\"human\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d93f74cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import Runnable, RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "def safe_parse(output):\n",
    "    try:\n",
    "        return parser.parse(output)\n",
    "    except Exception as e:\n",
    "        # If parsing fails, ask the model to correct its JSON\n",
    "        correction_prompt = f\"\"\"\n",
    "        The previous output was invalid JSON.\n",
    "        ERROR: {str(e)}\n",
    "\n",
    "        Please correct the output. Only return VALID JSON for a tool call.\n",
    "        Original output:\n",
    "        {output}\n",
    "        \"\"\"\n",
    "        fixed = model.invoke(correction_prompt).content\n",
    "        return parser.parse(fixed)\n",
    "\n",
    "safe_parser = RunnableLambda(safe_parse)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# FULL LCEL EXECUTION CHAIN\n",
    "# -------------------------------\n",
    "\n",
    "chain = (\n",
    "    prompt                      # 1. Prompt with few-shot for all tools\n",
    "    | model                     # 2. LLM generates JSON\n",
    "    | safe_parser               # 3. Safe JSON parser (auto-correct)\n",
    "    | RunnablePassthrough.assign(output=invoke_tool)  # 4. Execute the tool\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e3cec",
   "metadata": {},
   "source": [
    "ERROR HANDLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24c2b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_invoke_tool(tool_call_request: ToolCallRequest, config=None):\n",
    "    \"\"\"Safe tool executor with error handling and automatic correction.\"\"\"\n",
    "\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "\n",
    "    # Error 1 ‚Äî herramienta no existe\n",
    "    if tool_call_request[\"name\"] not in tool_name_to_tool:\n",
    "        return {\n",
    "            \"error\": f\"Tool '{tool_call_request['name']}' does not exist.\",\n",
    "            \"retry\": True\n",
    "        }\n",
    "\n",
    "    tool = tool_name_to_tool[tool_call_request[\"name\"]]\n",
    "\n",
    "    try:\n",
    "        # Error 2 ‚Äî argumentos incorrectos (tipos, nombres, etc.)\n",
    "        result = tool.invoke(tool_call_request[\"arguments\"], config=config)\n",
    "        return {\"output\": result, \"retry\": False}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"retry\": True,\n",
    "            \"tool\": tool_call_request[\"name\"],\n",
    "            \"arguments\": tool_call_request[\"arguments\"],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d71e335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "QUESTION: Divide 144 by 12.\n",
      "{'error': \"2 validation errors for divide\\nx\\n  Field required [type=missing, input_value={'dividend': 144, 'divisor': 12}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\\ny\\n  Field required [type=missing, input_value={'dividend': 144, 'divisor': 12}, input_type=dict]\\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\", 'retry': True, 'tool': 'divide', 'arguments': {'dividend': 144, 'divisor': 12}}\n",
      "\n",
      "==========================\n",
      "QUESTION: Raise 3 to the power of 7.\n",
      "{'error': \"Unknown tool 'pow'\", 'retry': True}\n",
      "\n",
      "==========================\n",
      "QUESTION: Compute 45 modulo 8.\n",
      "{'error': \"Unknown tool 'modulo_calculation'\", 'retry': True}\n",
      "\n",
      "==========================\n",
      "QUESTION: Subtract 50 minus 19.\n",
      "{'error': \"Unknown tool 'subtract'\", 'retry': True}\n",
      "\n",
      "==========================\n",
      "QUESTION: Divide 10 by 0.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 173\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==========================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQUESTION:\u001b[39m\u001b[38;5;124m\"\u001b[39m, q)\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28mprint\u001b[39m(chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: q}))\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3129\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3129\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4857\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4842\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[0;32m   4843\u001b[0m \n\u001b[0;32m   4844\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4854\u001b[0m \n\u001b[0;32m   4855\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4858\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4859\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4860\u001b[0m         ensure_config(config),\n\u001b[0;32m   4861\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4862\u001b[0m     )\n\u001b[0;32m   4863\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2046\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2048\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2050\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2051\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m                 func,\n\u001b[0;32m   2053\u001b[0m                 input_,\n\u001b[0;32m   2054\u001b[0m                 config,\n\u001b[0;32m   2055\u001b[0m                 run_manager,\n\u001b[0;32m   2056\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2057\u001b[0m             ),\n\u001b[0;32m   2058\u001b[0m         )\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2060\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4714\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4712\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4714\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4715\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, input_, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4716\u001b[0m     )\n\u001b[0;32m   4717\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[26], line 113\u001b[0m, in \u001b[0;36madapt_tool_call\u001b[1;34m(parsed)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parsed \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parsed:\n\u001b[0;32m    103\u001b[0m     fix_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124m    Your JSON is missing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\n\u001b[0;32m    105\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 113\u001b[0m     fixed \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minvoke(fix_prompt)\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m    114\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse(fixed)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments\u001b[39m\u001b[38;5;124m\"\u001b[39m: parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    119\u001b[0m }\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 1. IMPORTS\n",
    "# ====================================================\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Any, Dict, TypedDict\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. TOOLS\n",
    "# ====================================================\n",
    "@tool\n",
    "def divide(x: float, y: float) -> float:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "@tool\n",
    "def rest(x: int, y: int) -> int:\n",
    "    \"\"\"Subtract y from x.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "@tool\n",
    "def power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Raise a number to a given exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "@tool\n",
    "def modulo(x: int, y: int) -> int:\n",
    "    \"\"\"Compute x modulo y.\"\"\"\n",
    "    return x % y\n",
    "\n",
    "tools = [divide, rest, power, modulo]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 3. TOOL CALL STRUCTURE\n",
    "# ====================================================\n",
    "class ToolCallRequest(TypedDict):\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 4. SAFE TOOL EXECUTION\n",
    "# ====================================================\n",
    "def safe_invoke_tool(tool_call_request: ToolCallRequest, config=None):\n",
    "\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "\n",
    "    if tool_call_request[\"name\"] not in tool_name_to_tool:\n",
    "        return {\"error\": f\"Unknown tool '{tool_call_request['name']}'\", \"retry\": True}\n",
    "\n",
    "    tool = tool_name_to_tool[tool_call_request[\"name\"]]\n",
    "\n",
    "    try:\n",
    "        result = tool.invoke(tool_call_request[\"arguments\"], config=config)\n",
    "        return {\"output\": result, \"retry\": False}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"retry\": True,\n",
    "            \"tool\": tool_call_request[\"name\"],\n",
    "            \"arguments\": tool_call_request[\"arguments\"]\n",
    "        }\n",
    "\n",
    "safe_tool_executor = RunnableLambda(safe_invoke_tool)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 5. JSON SAFE PARSER\n",
    "# ====================================================\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "def safe_parse(output):\n",
    "    try:\n",
    "        return parser.parse(output)\n",
    "\n",
    "    except Exception as e:\n",
    "        fix_prompt = f\"\"\"\n",
    "        The JSON you returned was invalid.\n",
    "        ERROR: {str(e)}\n",
    "\n",
    "        Please return ONLY valid JSON.\n",
    "        Original output:\n",
    "        {output}\n",
    "        \"\"\"\n",
    "        fixed = model.invoke(fix_prompt).content\n",
    "        return parser.parse(fixed)\n",
    "\n",
    "safe_parser = RunnableLambda(safe_parse)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 6. ADAPTER FROM \"tool\"/\"args\" ‚Üí \"name\"/\"arguments\"\n",
    "# ====================================================\n",
    "def adapt_tool_call(parsed):\n",
    "    \"\"\"Ensure valid structure and adapt keys.\"\"\"\n",
    "    \n",
    "    if \"tool\" not in parsed or \"args\" not in parsed:\n",
    "        fix_prompt = f\"\"\"\n",
    "        Your JSON is missing 'tool' or 'args'.\n",
    "\n",
    "        Required format:\n",
    "        {{ \"tool\": \"<name>\", \"args\": {{ ... }} }}\n",
    "\n",
    "        Your incorrect output:\n",
    "        {parsed}\n",
    "        \"\"\"\n",
    "\n",
    "        fixed = model.invoke(fix_prompt).content\n",
    "        parsed = parser.parse(fixed)\n",
    "\n",
    "    return {\n",
    "        \"name\": parsed[\"tool\"],\n",
    "        \"arguments\": parsed[\"args\"]\n",
    "    }\n",
    "\n",
    "adapted_tool_call = RunnableLambda(adapt_tool_call)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 7. ESCAPED PROMPT (NO ERROR)\n",
    "# ====================================================\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "     You are a math assistant. You MUST output ONLY JSON.\n",
    "\n",
    "     JSON MUST contain:\n",
    "       - \"tool\"\n",
    "       - \"args\"\n",
    "\n",
    "     Example:\n",
    "     {{ \"tool\": \"divide\", \"args\": {{ \"x\": 10, \"y\": 2 }} }}\n",
    "\n",
    "     No explanations. Only JSON.\n",
    "     \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 8. FINAL LCEL CHAIN\n",
    "# ====================================================\n",
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | safe_parser\n",
    "    | adapted_tool_call\n",
    "    | safe_tool_executor\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 9. TEST QUESTIONS\n",
    "# ====================================================\n",
    "questions = [\n",
    "    \"Divide 144 by 12.\",\n",
    "    \"Raise 3 to the power of 7.\",\n",
    "    \"Compute 45 modulo 8.\",\n",
    "    \"Subtract 50 minus 19.\",\n",
    "    \"Divide 10 by 0.\",          # ERROR TEST\n",
    "    \"Use the multiply tool.\"    # ERROR TEST\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\"QUESTION:\", q)\n",
    "    print(chain.invoke({\"input\": q}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a627fcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "QUESTION: Divide 144 by 12.\n",
      "{'output': 12.0, 'retry': False}\n",
      "\n",
      "==========================\n",
      "QUESTION: Raise 3 to the power of 7.\n",
      "{'output': 2187.0, 'retry': False}\n",
      "\n",
      "==========================\n",
      "QUESTION: Compute 45 modulo 8.\n",
      "{'output': 5, 'retry': False}\n",
      "\n",
      "==========================\n",
      "QUESTION: Subtract 50 minus 19.\n",
      "{'error': '1 validation error for modulo\\ny\\n  Input should be a valid integer [type=int_type, input_value=None, input_type=NoneType]\\n    For further information visit https://errors.pydantic.dev/2.10/v/int_type', 'retry': True, 'tool': 'modulo', 'arguments': {'x': '-31', 'y': None}}\n",
      "\n",
      "==========================\n",
      "QUESTION: Divide 10 by 0.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 215\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==========================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQUESTION:\u001b[39m\u001b[38;5;124m\"\u001b[39m, q)\n\u001b[1;32m--> 215\u001b[0m \u001b[38;5;28mprint\u001b[39m(chain\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: q}))\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3129\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3127\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3128\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3129\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config)\n\u001b[0;32m   3130\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4857\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4842\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this `Runnable` synchronously.\u001b[39;00m\n\u001b[0;32m   4843\u001b[0m \n\u001b[0;32m   4844\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4854\u001b[0m \n\u001b[0;32m   4855\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4858\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4859\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4860\u001b[0m         ensure_config(config),\n\u001b[0;32m   4861\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4862\u001b[0m     )\n\u001b[0;32m   4863\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:2050\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   2046\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   2047\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   2048\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   2049\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2050\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   2051\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m                 func,\n\u001b[0;32m   2053\u001b[0m                 input_,\n\u001b[0;32m   2054\u001b[0m                 config,\n\u001b[0;32m   2055\u001b[0m                 run_manager,\n\u001b[0;32m   2056\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2057\u001b[0m             ),\n\u001b[0;32m   2058\u001b[0m         )\n\u001b[0;32m   2059\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   2060\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\base.py:4714\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4712\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4713\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4714\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4715\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, input_, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4716\u001b[0m     )\n\u001b[0;32m   4717\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4718\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32md:\\DESCARGAS 2.0\\Anaconda\\Lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[28], line 138\u001b[0m, in \u001b[0;36mvalidate_and_fix\u001b[1;34m(parsed)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# Missing fields\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parsed \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m parsed:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fix_with_llm(parsed, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m tool \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    141\u001b[0m args \u001b[38;5;241m=\u001b[39m parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[1;32mIn[28], line 130\u001b[0m, in \u001b[0;36mfix_with_llm\u001b[1;34m(parsed, error_message)\u001b[0m\n\u001b[0;32m    127\u001b[0m corrected \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39minvoke(correction_prompt)  \u001b[38;5;66;03m# FIXED\u001b[39;00m\n\u001b[0;32m    128\u001b[0m corrected_json \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse(corrected)\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m validate_and_fix(corrected_json)\n",
      "Cell \u001b[1;32mIn[28], line 149\u001b[0m, in \u001b[0;36mvalidate_and_fix\u001b[1;34m(parsed)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Wrong argument names\u001b[39;00m\n\u001b[0;32m    148\u001b[0m required \u001b[38;5;241m=\u001b[39m ALLOWED_TOOLS[tool]\n\u001b[1;32m--> 149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(args\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28msorted\u001b[39m(required):\n\u001b[0;32m    150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fix_with_llm(\n\u001b[0;32m    151\u001b[0m         parsed,\n\u001b[0;32m    152\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect arguments for tool \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Required: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrequired\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    153\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# VALID ‚Üí return in proper format\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 1. IMPORTS\n",
    "# ====================================================\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Any, Dict, TypedDict\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. TOOLS\n",
    "# ====================================================\n",
    "@tool\n",
    "def divide(x: float, y: float) -> float:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "@tool\n",
    "def rest(x: int, y: int) -> int:\n",
    "    \"\"\"Subtract y from x.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "@tool\n",
    "def power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Raise a number to a given exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "@tool\n",
    "def modulo(x: int, y: int) -> int:\n",
    "    \"\"\"Compute x modulo y.\"\"\"\n",
    "    return x % y\n",
    "\n",
    "tools = [divide, rest, power, modulo]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 3. TOOL CALL STRUCTURE\n",
    "# ====================================================\n",
    "class ToolCallRequest(TypedDict):\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 4. SAFE TOOL EXECUTION\n",
    "# ====================================================\n",
    "def safe_invoke_tool(tool_call_request: ToolCallRequest, config=None):\n",
    "\n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "\n",
    "    if tool_call_request[\"name\"] not in tool_name_to_tool:\n",
    "        return {\"error\": f\"Unknown tool '{tool_call_request['name']}'\", \"retry\": True}\n",
    "\n",
    "    tool = tool_name_to_tool[tool_call_request[\"name\"]]\n",
    "\n",
    "    try:\n",
    "        result = tool.invoke(tool_call_request[\"arguments\"], config=config)\n",
    "        return {\"output\": result, \"retry\": False}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"error\": str(e),\n",
    "            \"retry\": True,\n",
    "            \"tool\": tool_call_request[\"name\"],\n",
    "            \"arguments\": tool_call_request[\"arguments\"]\n",
    "        }\n",
    "\n",
    "safe_tool_executor = RunnableLambda(safe_invoke_tool)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 5. JSON SAFE PARSER (NO .content)\n",
    "# ====================================================\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "def safe_parse(output):\n",
    "    try:\n",
    "        return parser.parse(output)\n",
    "\n",
    "    except Exception as e:\n",
    "        fix_prompt = f\"\"\"\n",
    "        The JSON you returned was invalid.\n",
    "        ERROR: {str(e)}\n",
    "\n",
    "        Please return ONLY valid JSON.\n",
    "        Original output:\n",
    "        {output}\n",
    "        \"\"\"\n",
    "        corrected = model.invoke(fix_prompt)  # FIXED\n",
    "        return parser.parse(corrected)\n",
    "\n",
    "safe_parser = RunnableLambda(safe_parse)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 6. HARDENED VALIDATOR WITH AUTO-CORRECTION\n",
    "# ====================================================\n",
    "ALLOWED_TOOLS = {\n",
    "    \"divide\": [\"x\", \"y\"],\n",
    "    \"rest\": [\"x\", \"y\"],\n",
    "    \"power\": [\"base\", \"exponent\"],\n",
    "    \"modulo\": [\"x\", \"y\"]\n",
    "}\n",
    "\n",
    "\n",
    "def fix_with_llm(parsed, error_message):\n",
    "\n",
    "    correction_prompt = f\"\"\"\n",
    "    Your previous JSON tool call was invalid.\n",
    "\n",
    "    ERROR:\n",
    "    {error_message}\n",
    "\n",
    "    Allowed tools:\n",
    "    divide(x, y)\n",
    "    rest(x, y)\n",
    "    power(base, exponent)\n",
    "    modulo(x, y)\n",
    "\n",
    "    Your incorrect output:\n",
    "    {parsed}\n",
    "\n",
    "    Return ONLY fixed JSON. No text.\n",
    "    \"\"\"\n",
    "\n",
    "    corrected = model.invoke(correction_prompt)  # FIXED\n",
    "    corrected_json = parser.parse(corrected)\n",
    "\n",
    "    return validate_and_fix(corrected_json)\n",
    "\n",
    "\n",
    "def validate_and_fix(parsed):\n",
    "    \"\"\"Validate tool name + args; LLM auto-correct if needed.\"\"\"\n",
    "\n",
    "    # Missing fields\n",
    "    if \"tool\" not in parsed or \"args\" not in parsed:\n",
    "        return fix_with_llm(parsed, \"Missing 'tool' or 'args'.\")\n",
    "\n",
    "    tool = parsed[\"tool\"]\n",
    "    args = parsed[\"args\"]\n",
    "\n",
    "    # Unknown tool\n",
    "    if tool not in ALLOWED_TOOLS:\n",
    "        return fix_with_llm(parsed, f\"Unknown tool '{tool}'.\")\n",
    "\n",
    "    # Wrong argument names\n",
    "    required = ALLOWED_TOOLS[tool]\n",
    "    if sorted(args.keys()) != sorted(required):\n",
    "        return fix_with_llm(\n",
    "            parsed,\n",
    "            f\"Incorrect arguments for tool '{tool}'. Required: {required}\"\n",
    "        )\n",
    "\n",
    "    # VALID ‚Üí return in proper format\n",
    "    return {\n",
    "        \"name\": tool,\n",
    "        \"arguments\": args\n",
    "    }\n",
    "\n",
    "\n",
    "validator = RunnableLambda(validate_and_fix)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 7. ESCAPED PROMPT (NO PROMPT VARIABLE ERRORS)\n",
    "# ====================================================\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "     You are a math assistant. You MUST output ONLY JSON.\n",
    "\n",
    "     JSON MUST contain:\n",
    "       - \"tool\"\n",
    "       - \"args\"\n",
    "\n",
    "     Example:\n",
    "     {{ \"tool\": \"divide\", \"args\": {{ \"x\": 10, \"y\": 2 }} }}\n",
    "\n",
    "     No explanations. Only JSON.\n",
    "     \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 8. FINAL LCEL CHAIN\n",
    "# ====================================================\n",
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | safe_parser\n",
    "    | validator\n",
    "    | safe_tool_executor\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 9. TEST QUESTIONS\n",
    "# ====================================================\n",
    "questions = [\n",
    "    \"Divide 144 by 12.\",\n",
    "    \"Raise 3 to the power of 7.\",\n",
    "    \"Compute 45 modulo 8.\",\n",
    "    \"Subtract 50 minus 19.\",\n",
    "    \"Divide 10 by 0.\",            # ERROR TEST\n",
    "    \"Use the multiply tool.\",     # ERROR TEST\n",
    "    \"What is the remainder when 123 is divided by 7?\"  # Modulo test\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(\"\\n==========================\")\n",
    "    print(\"QUESTION:\", q)\n",
    "    print(chain.invoke({\"input\": q}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fc55cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QUESTION: Divide 144 by 12.\n",
      "{'output': 12.0, 'retry': False}\n",
      "\n",
      "QUESTION: Raise 3 to the power of 7.\n",
      "{'output': 2187.0, 'retry': False}\n",
      "\n",
      "QUESTION: Compute 45 modulo 8.\n",
      "{'output': 5, 'retry': False}\n",
      "\n",
      "QUESTION: Subtract 50 minus 19.\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# 1. IMPORTS\n",
    "# ====================================================\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from typing import Any, Dict, TypedDict\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 2. JSON SCRUBBER (extracts valid JSON)\n",
    "# ====================================================\n",
    "def extract_json(text):\n",
    "    \"\"\"Extract JSON object from the model output; auto-correct if needed.\"\"\"\n",
    "    try:\n",
    "        match = re.search(r\"\\{.*\\}\", text, re.DOTALL)\n",
    "        if match:\n",
    "            return json.loads(match.group(0))\n",
    "        raise ValueError(\"No JSON found in the output.\")\n",
    "    except Exception as e:\n",
    "        fix_prompt = f\"\"\"\n",
    "        The output was NOT valid JSON.\n",
    "\n",
    "        ERROR:\n",
    "        {e}\n",
    "\n",
    "        OUTPUT:\n",
    "        {text}\n",
    "\n",
    "        Return ONLY valid JSON in this format:\n",
    "        {{\n",
    "            \"tool\": \"divide|rest|power|modulo\",\n",
    "            \"args\": {{\n",
    "                \"key\": value,\n",
    "                \"key\": value\n",
    "            }}\n",
    "        }}\n",
    "        \"\"\"\n",
    "        corrected = model.invoke(fix_prompt)\n",
    "        return extract_json(corrected)\n",
    "\n",
    "safe_parser = RunnableLambda(lambda text: extract_json(text))\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 3. TOOLS (WITH REQUIRED DOCSTRINGS)\n",
    "# ====================================================\n",
    "@tool\n",
    "def divide(x: float, y: float) -> float:\n",
    "    \"\"\"Divide x by y.\"\"\"\n",
    "    return x / y\n",
    "\n",
    "@tool\n",
    "def rest(x: int, y: int) -> int:\n",
    "    \"\"\"Subtract y from x.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "@tool\n",
    "def power(base: float, exponent: float) -> float:\n",
    "    \"\"\"Raise base to the exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "@tool\n",
    "def modulo(x: int, y: int) -> int:\n",
    "    \"\"\"Return x modulo y.\"\"\"\n",
    "    return x % y\n",
    "\n",
    "tools = [divide, rest, power, modulo]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 4. TOOL CALL STRUCTURE\n",
    "# ====================================================\n",
    "class ToolCallRequest(TypedDict):\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 5. TOOL EXECUTION\n",
    "# ====================================================\n",
    "def execute_tool(request):\n",
    "    tool_map = {t.name: t for t in tools}\n",
    "\n",
    "    # Tool not found\n",
    "    if request[\"name\"] not in tool_map:\n",
    "        return {\"error\": f\"Unknown tool '{request['name']}'\", \"retry\": True}\n",
    "\n",
    "    # Execute tool safely\n",
    "    try:\n",
    "        output = tool_map[request[\"name\"]].invoke(request[\"arguments\"])\n",
    "        return {\"output\": output, \"retry\": False}\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e), \"retry\": True}\n",
    "\n",
    "safe_tool_executor = RunnableLambda(execute_tool)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 6. VALIDATION + AUTO-CORRECTION\n",
    "# ====================================================\n",
    "ALLOWED_TOOLS = {\n",
    "    \"divide\": [\"x\", \"y\"],\n",
    "    \"rest\": [\"x\", \"y\"],\n",
    "    \"power\": [\"base\", \"exponent\"],\n",
    "    \"modulo\": [\"x\", \"y\"]\n",
    "}\n",
    "\n",
    "def fix_with_llm(parsed, error):\n",
    "    correction_prompt = f\"\"\"\n",
    "    Your JSON tool call is INVALID.\n",
    "\n",
    "    ERROR:\n",
    "    {error}\n",
    "\n",
    "    Allowed tools:\n",
    "       divide(x, y)\n",
    "       rest(x, y)\n",
    "       power(base, exponent)\n",
    "       modulo(x, y)\n",
    "\n",
    "    Your incorrect JSON:\n",
    "    {parsed}\n",
    "\n",
    "    Return ONLY valid JSON:\n",
    "    {{\n",
    "        \"tool\": \"divide|rest|power|modulo\",\n",
    "        \"args\": {{\n",
    "            \"arg1\": number,\n",
    "            \"arg2\": number\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    corrected = model.invoke(correction_prompt)\n",
    "    corrected_json = extract_json(corrected)\n",
    "    return validate_and_fix(corrected_json)\n",
    "\n",
    "def validate_and_fix(parsed):\n",
    "    \"\"\"Ensures JSON has the correct tool + correct argument names.\"\"\"\n",
    "\n",
    "    # --- Missing keys ---\n",
    "    if \"tool\" not in parsed or \"args\" not in parsed:\n",
    "        return fix_with_llm(parsed, \"Missing 'tool' or 'args'.\")\n",
    "\n",
    "    tool = parsed[\"tool\"]\n",
    "    args = parsed[\"args\"]\n",
    "\n",
    "    # --- Unknown tool ---\n",
    "    if tool not in ALLOWED_TOOLS:\n",
    "        return fix_with_llm(parsed, f\"Unknown tool '{tool}'.\")\n",
    "\n",
    "    required = ALLOWED_TOOLS[tool]\n",
    "\n",
    "    # --- args is a LIST ‚Üí convert to dict automatically ---\n",
    "    if isinstance(args, list):\n",
    "        if len(args) != len(required):\n",
    "            return fix_with_llm(parsed, f\"Wrong number of args for {tool}.\")\n",
    "        args = {required[i]: args[i] for i in range(len(required))}\n",
    "\n",
    "    # --- args is not a dict ---\n",
    "    if not isinstance(args, dict):\n",
    "        return fix_with_llm(parsed, \"'args' must be a dict.\")\n",
    "\n",
    "    # --- wrong argument names ---\n",
    "    if sorted(args.keys()) != sorted(required):\n",
    "        return fix_with_llm(parsed, f\"Incorrect argument names for {tool}.\")\n",
    "\n",
    "    # SUCCESS\n",
    "    return {\"name\": tool, \"arguments\": args}\n",
    "\n",
    "validator = RunnableLambda(validate_and_fix)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 7. ESCAPED PROMPT (IMPORTANT)\n",
    "# ====================================================\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"\n",
    "     You MUST output ONLY JSON.\n",
    "\n",
    "     JSON FORMAT:\n",
    "     {{\n",
    "        \"tool\": \"divide|rest|power|modulo\",\n",
    "        \"args\": {{\n",
    "            \"arg1\": number,\n",
    "            \"arg2\": number\n",
    "        }}\n",
    "     }}\n",
    "\n",
    "     Example:\n",
    "     {{\n",
    "         \"tool\": \"divide\",\n",
    "         \"args\": {{\n",
    "             \"x\": 10,\n",
    "             \"y\": 2\n",
    "         }}\n",
    "     }}\n",
    "\n",
    "     No explanations.\n",
    "     No markdown.\n",
    "     No extra text.\n",
    "     \"\"\"\n",
    "    ),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 8. FINAL LCEL CHAIN\n",
    "# ====================================================\n",
    "chain = (\n",
    "    prompt\n",
    "    | model\n",
    "    | safe_parser\n",
    "    | validator\n",
    "    | safe_tool_executor\n",
    ")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# 9. TEST QUESTIONS\n",
    "# ====================================================\n",
    "tests = [\n",
    "    \"Divide 144 by 12.\",\n",
    "    \"Raise 3 to the power of 7.\",\n",
    "    \"Compute 45 modulo 8.\",\n",
    "    \"Subtract 50 minus 19.\",\n",
    "    \"Divide 10 by 0.\",\n",
    "    \"Use multiply on 3 and 4.\",\n",
    "    \"Call divide with [144,12].\"\n",
    "]\n",
    "\n",
    "for q in tests:\n",
    "    print(\"\\nQUESTION:\", q)\n",
    "    print(chain.invoke({\"input\": q}))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
